# -*- coding: utf-8 -*-
"""Lambda_Function.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b9GleXOfi_9HqZNhLz91oJmUMuoxp7L6
"""

import json
import boto3
import base64

# --------- First Lambda: serializeImageData ---------
# This function downloads an image file from S3,
# encodes it to base64, and passes it downstream.

s3 = boto3.client('s3')

def lambda_handler(event, context):
    # Get the S3 bucket and key from the input event
    key = event["s3_key"]
    bucket = event["s3_bucket"]

    # Download file from S3 to Lambda's /tmp directory
    download_path = '/tmp/image.png'
    s3.download_file(bucket, key, download_path)

    # Read the image file and encode it to base64 string
    with open(download_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')

    # Return the event with the encoded image data added
    return {
        'statusCode': 200,
        'body': {
            "image_data": image_data,
            "s3_bucket": bucket,
            "s3_key": key,
            "inferences": []  # empty list initially, to be filled by next Lambda
        }
    }


# --------- Second Lambda: classifyImage ---------
# This function decodes the base64 image, sends it to the SageMaker endpoint,
# receives the prediction (inferences), and adds them to the event.

ENDPOINT = "image-classification-2025-08-10-17-33-43-575"
runtime = boto3.client('sagemaker-runtime')

def lambda_handler(event, context):
    # The event body might be a string, so parse it to dict if needed
    body = event.get("body")
    if isinstance(body, str):
        body = json.loads(body)

    # Ensure image_data is present
    if "image_data" not in body:
        raise ValueError("Missing 'image_data' in input event body")

    # Decode the base64 image back to bytes
    image_data_b64 = body["image_data"]
    image_bytes = base64.b64decode(image_data_b64)

    # Invoke SageMaker endpoint with the image bytes
    response = runtime.invoke_endpoint(
        EndpointName=ENDPOINT,
        ContentType='image/png',  # The model expects PNG images
        Body=image_bytes
    )

    # Read the response and decode it to a Python list
    result = response['Body'].read()
    inferences_str = result.decode('utf-8')
    inferences_list = json.loads(inferences_str)

    # Add the inferences to the event body
    body["inferences"] = inferences_list

    # Return updated event body for next Lambda
    return {
        'statusCode': 200,
        'body': body
    }


# --------- Third Lambda: filterInferences ---------
# This function checks if any inference score meets or exceeds the confidence threshold.
# If yes, passes those filtered inferences on; otherwise, it returns a message.

CONFIDENCE_THRESHOLD = 0.9

def lambda_handler(event, context):
    # The inferences should be present in the event dictionary
    inferences = event.get("inferences", [])

    # Filter the scores that meet or exceed the confidence threshold
    filtered = [score for score in inferences if score >= CONFIDENCE_THRESHOLD]

    # If none meet the threshold, return a message indicating so
    if not filtered:
        return {
            "statusCode": 200,
            "body": {
                "message": "No inferences above confidence threshold.",
                "threshold": CONFIDENCE_THRESHOLD,
                "inferences": inferences
            }
        }

    # Return the filtered high-confidence inferences
    return {
        "statusCode": 200,
        "body": {
            "filtered_inferences": filtered,
            "threshold": CONFIDENCE_THRESHOLD
        }
    }